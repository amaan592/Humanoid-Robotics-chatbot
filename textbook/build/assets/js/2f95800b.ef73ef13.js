"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[6503],{7111:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>a,toc:()=>d});var t=o(4848),s=o(8453);const i={sidebar_position:1,title:"Glossary of Robotics Terminology"},r="Glossary of Robotics Terminology",a={id:"standards/glossary",title:"Glossary of Robotics Terminology",description:"This glossary provides standardized definitions for key terms used throughout the Physical AI & Humanoid Robotics textbook.",source:"@site/docs/standards/glossary.md",sourceDirName:"standards",slug:"/standards/glossary",permalink:"/docs/standards/glossary",draft:!1,unlisted:!1,editUrl:"https://github.com/your-username/physical-ai-humanoid-robotics-textbook/edit/main/docs/standards/glossary.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1,title:"Glossary of Robotics Terminology"},sidebar:"textbookSidebar",previous:{title:"Academic Tone and Technical Precision Standards",permalink:"/docs/standards/academic-tone"},next:{title:"Learning Outcome Format and Measurement Criteria",permalink:"/docs/standards/learning-outcomes"}},l={},d=[{value:"A",id:"a",level:2},{value:"B",id:"b",level:2},{value:"C",id:"c",level:2},{value:"E",id:"e",level:2},{value:"G",id:"g",level:2},{value:"H",id:"h",level:2},{value:"I",id:"i",level:2},{value:"L",id:"l",level:2},{value:"M",id:"m",level:2},{value:"N",id:"n",level:2},{value:"P",id:"p",level:2},{value:"R",id:"r",level:2},{value:"S",id:"s",level:2},{value:"T",id:"t",level:2},{value:"U",id:"u",level:2},{value:"V",id:"v",level:2},{value:"W",id:"w",level:2}];function c(e){const n={h1:"h1",h2:"h2",p:"p",strong:"strong",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"glossary-of-robotics-terminology",children:"Glossary of Robotics Terminology"}),"\n",(0,t.jsx)(n.p,{children:"This glossary provides standardized definitions for key terms used throughout the Physical AI & Humanoid Robotics textbook."}),"\n",(0,t.jsx)(n.h2,{id:"a",children:"A"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Autonomous Control"}),": The ability of a robot to perform tasks without human intervention, typically involving perception, planning, and actuation systems working together."]}),"\n",(0,t.jsx)(n.h2,{id:"b",children:"B"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Behavior-Based Robotics"}),": An approach to robotics that structures robot control as a collection of behaviors that can be combined and coordinated."]}),"\n",(0,t.jsx)(n.h2,{id:"c",children:"C"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Control Architecture"}),": The organizational structure of a robot's control system, defining how different control components interact and coordinate."]}),"\n",(0,t.jsx)(n.h2,{id:"e",children:"E"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Embodied Cognition"}),": The theory that cognitive processes are deeply rooted in the body's interactions with the environment."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Embodied Intelligence"}),": Intelligence that emerges from the interaction between a physical agent and its environment, where the body plays a crucial role in cognitive processes."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Environment Modeling"}),": The process of creating digital representations of the physical environment for simulation or planning purposes."]}),"\n",(0,t.jsx)(n.h2,{id:"g",children:"G"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Gazebo"}),": A robot simulation environment that provides realistic sensor simulation and multiple physics engines for complex robot scenarios in 3D worlds."]}),"\n",(0,t.jsx)(n.h2,{id:"h",children:"H"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Humanoid Robot"}),": A robot with human-like form and capabilities, typically featuring legs, arms, and a head with human-like degrees of freedom."]}),"\n",(0,t.jsx)(n.h2,{id:"i",children:"I"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Inertial Measurement Unit (IMU)"}),": A device that measures and reports a body's specific force, angular rate, and sometimes the magnetic field surrounding the body."]}),"\n",(0,t.jsx)(n.h2,{id:"l",children:"L"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Locomotion"}),": The act of moving from one place to another, particularly relevant for legged robots and humanoid systems."]}),"\n",(0,t.jsx)(n.h2,{id:"m",children:"M"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Morphological Computation"}),": The idea that the physical form and material properties of a robot contribute to its computational and control processes."]}),"\n",(0,t.jsx)(n.h2,{id:"n",children:"N"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"NVIDIA Isaac"}),": A robotics platform and tools ecosystem that provides simulation, perception, and control capabilities for robotics applications."]}),"\n",(0,t.jsx)(n.h2,{id:"p",children:"P"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Perception"}),": The process of interpreting sensory information to understand the environment and the robot's state within it."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Physical AI"}),": Artificial intelligence systems that exist and operate in the physical world, interacting with real environments through sensors and actuators."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Proprioceptive Sensors"}),": Sensors that measure internal state of the robot, such as joint angles, motor currents, and IMU data."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Proactive Control"}),": Control systems that anticipate future states and act accordingly, rather than simply reacting to current inputs."]}),"\n",(0,t.jsx)(n.h2,{id:"r",children:"R"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ROS (Robot Operating System)"}),": A flexible framework for writing robot software, providing a collection of tools, libraries, and conventions."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ROS 2"}),": The second generation of the Robot Operating System with improved architecture for real-world deployment."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Reactive Behavior"}),": Robot behaviors that respond directly to environmental stimuli without planning or anticipation."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Request/Response"}),": A synchronous communication pattern in ROS where one node sends a request and waits for a response from another node."]}),"\n",(0,t.jsx)(n.h2,{id:"s",children:"S"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Sensor Fusion"}),": The process of combining data from multiple sensors to achieve better accuracy and reliability than individual sensors can provide."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Simulation-to-Reality Transfer"}),": The process of applying knowledge, behaviors, or control policies learned in simulation to real-world robotic systems."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"State Estimation"}),": The process of determining the internal state of a robot based on sensor measurements and control inputs."]}),"\n",(0,t.jsx)(n.h2,{id:"t",children:"T"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"TF (Transform Framework)"}),": A component of ROS that enables robots to keep track of coordinate frames over time."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Topics"}),": In ROS, streams of messages passed between nodes implementing a publish/subscribe communication pattern."]}),"\n",(0,t.jsx)(n.h2,{id:"u",children:"U"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"URDF (Unified Robot Description Format)"}),": An XML format for representing a robot model including kinematic and visual information."]}),"\n",(0,t.jsx)(n.h2,{id:"v",children:"V"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Visual Perception"}),": The process of interpreting visual information from cameras to understand the environment and objects within it."]}),"\n",(0,t.jsx)(n.h2,{id:"w",children:"W"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Whole-Body Control"}),": A control approach that considers the entire robot's dynamics and constraints simultaneously rather than controlling individual parts separately."]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>r,x:()=>a});var t=o(6540);const s={},i=t.createContext(s);function r(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);